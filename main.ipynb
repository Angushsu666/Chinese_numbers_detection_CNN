{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fd54f43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_64 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_64 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_65 (MaxPoolin  (None, 5, 5, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_96 (Dropout)        (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_97 (Dropout)        (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 128)               204928    \n",
      "                                                                 \n",
      " dropout_98 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 1.2597 - accuracy: 0.6000 - val_loss: 0.3433 - val_accuracy: 0.9020\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.3335 - accuracy: 0.8971 - val_loss: 0.2383 - val_accuracy: 0.9224\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.2069 - accuracy: 0.9351 - val_loss: 0.1261 - val_accuracy: 0.9429\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.1454 - accuracy: 0.9519 - val_loss: 0.0991 - val_accuracy: 0.9592\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.1197 - accuracy: 0.9583 - val_loss: 0.1067 - val_accuracy: 0.9592\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0887 - accuracy: 0.9710 - val_loss: 0.1249 - val_accuracy: 0.9551\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0910 - accuracy: 0.9687 - val_loss: 0.0921 - val_accuracy: 0.9633\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.0831 - accuracy: 0.9728 - val_loss: 0.0865 - val_accuracy: 0.9673\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 3s 39ms/step - loss: 0.0791 - accuracy: 0.9701 - val_loss: 0.0804 - val_accuracy: 0.9714\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.0719 - accuracy: 0.9737 - val_loss: 0.0810 - val_accuracy: 0.9755\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.0693 - accuracy: 0.9764 - val_loss: 0.0860 - val_accuracy: 0.9673\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.0610 - accuracy: 0.9769 - val_loss: 0.1002 - val_accuracy: 0.9592\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.0661 - accuracy: 0.9760 - val_loss: 0.1148 - val_accuracy: 0.9673\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 0.0632 - accuracy: 0.9760 - val_loss: 0.1112 - val_accuracy: 0.9633\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.0730 - accuracy: 0.9723 - val_loss: 0.0575 - val_accuracy: 0.9714\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.0672 - accuracy: 0.9764 - val_loss: 0.1087 - val_accuracy: 0.9673\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0630 - accuracy: 0.9764 - val_loss: 0.0984 - val_accuracy: 0.9714\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0674 - accuracy: 0.9751 - val_loss: 0.1324 - val_accuracy: 0.9673\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0644 - accuracy: 0.9782 - val_loss: 0.0603 - val_accuracy: 0.9755\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.0569 - accuracy: 0.9787 - val_loss: 0.0761 - val_accuracy: 0.9755\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0570 - accuracy: 0.9791 - val_loss: 0.0761 - val_accuracy: 0.9837\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0571 - accuracy: 0.9782 - val_loss: 0.1096 - val_accuracy: 0.9673\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0563 - accuracy: 0.9814 - val_loss: 0.0621 - val_accuracy: 0.9755\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0548 - accuracy: 0.9796 - val_loss: 0.0811 - val_accuracy: 0.9714\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.0599 - accuracy: 0.9778 - val_loss: 0.0567 - val_accuracy: 0.9796\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 3s 40ms/step - loss: 0.0837 - accuracy: 0.9701 - val_loss: 0.1011 - val_accuracy: 0.9673\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.0670 - accuracy: 0.9741 - val_loss: 0.0635 - val_accuracy: 0.9755\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 0.0640 - accuracy: 0.9782 - val_loss: 0.0587 - val_accuracy: 0.9837\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.0585 - accuracy: 0.9800 - val_loss: 0.0837 - val_accuracy: 0.9714\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.0585 - accuracy: 0.9773 - val_loss: 0.1152 - val_accuracy: 0.9633\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.0575 - accuracy: 0.9810 - val_loss: 0.0790 - val_accuracy: 0.9796\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0577 - accuracy: 0.9796 - val_loss: 0.0974 - val_accuracy: 0.9755\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0563 - accuracy: 0.9850 - val_loss: 0.0574 - val_accuracy: 0.9796\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0505 - accuracy: 0.9859 - val_loss: 0.0789 - val_accuracy: 0.9673\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0491 - accuracy: 0.9868 - val_loss: 0.0925 - val_accuracy: 0.9755\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0488 - accuracy: 0.9864 - val_loss: 0.0572 - val_accuracy: 0.9673\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.0486 - accuracy: 0.9882 - val_loss: 0.1129 - val_accuracy: 0.9673\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0511 - accuracy: 0.9873 - val_loss: 0.1102 - val_accuracy: 0.9673\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.0432 - accuracy: 0.9873 - val_loss: 0.1465 - val_accuracy: 0.9796\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0456 - accuracy: 0.9855 - val_loss: 0.0482 - val_accuracy: 0.9796\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0407 - accuracy: 0.9900 - val_loss: 0.0746 - val_accuracy: 0.9796\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.0324 - accuracy: 0.9909 - val_loss: 0.0707 - val_accuracy: 0.9796\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0265 - accuracy: 0.9950 - val_loss: 0.0811 - val_accuracy: 0.9714\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.0295 - accuracy: 0.9918 - val_loss: 0.0835 - val_accuracy: 0.9714\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0282 - accuracy: 0.9937 - val_loss: 0.0825 - val_accuracy: 0.9714\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0198 - accuracy: 0.9959 - val_loss: 0.0739 - val_accuracy: 0.9755\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.0167 - accuracy: 0.9982 - val_loss: 0.0751 - val_accuracy: 0.9714\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.0789 - val_accuracy: 0.9673\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.0185 - accuracy: 0.9964 - val_loss: 0.0733 - val_accuracy: 0.9837\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0125 - accuracy: 0.9973 - val_loss: 0.0939 - val_accuracy: 0.9755\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0171 - accuracy: 0.9959 - val_loss: 0.0965 - val_accuracy: 0.9755\n",
      "Epoch 52/200\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0207 - accuracy: 0.9923 - val_loss: 0.1485 - val_accuracy: 0.9633\n",
      "Epoch 53/200\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.1348 - val_accuracy: 0.9673\n",
      "Epoch 54/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0079 - accuracy: 0.9995 - val_loss: 0.1192 - val_accuracy: 0.9673\n",
      "Epoch 55/200\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.0092 - accuracy: 0.9986 - val_loss: 0.0824 - val_accuracy: 0.9755\n",
      "Epoch 56/200\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0067 - accuracy: 0.9991 - val_loss: 0.0737 - val_accuracy: 0.9755\n",
      "Epoch 57/200\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1280 - val_accuracy: 0.9714\n",
      "Epoch 58/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.1038 - val_accuracy: 0.9673\n",
      "Epoch 59/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.1108 - val_accuracy: 0.9796\n",
      "Epoch 60/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 0.1161 - val_accuracy: 0.9755\n",
      "Epoch 61/200\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1090 - val_accuracy: 0.9755\n",
      "Epoch 62/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 0.0957 - val_accuracy: 0.9755\n",
      "Epoch 63/200\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.1423 - val_accuracy: 0.9755\n",
      "Epoch 64/200\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0236 - accuracy: 0.9937 - val_loss: 0.2573 - val_accuracy: 0.9592\n",
      "Epoch 65/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0219 - accuracy: 0.9937 - val_loss: 0.0560 - val_accuracy: 0.9755\n",
      "Epoch 66/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0770 - val_accuracy: 0.9673\n",
      "Epoch 67/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0104 - accuracy: 0.9986 - val_loss: 0.0783 - val_accuracy: 0.9714\n",
      "Epoch 68/200\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0524 - val_accuracy: 0.9837\n",
      "Epoch 69/200\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0621 - val_accuracy: 0.9796\n",
      "Epoch 70/200\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9796\n",
      "Epoch 71/200\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9796\n",
      "Epoch 72/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9796\n",
      "Epoch 73/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0619 - val_accuracy: 0.9796\n",
      "Epoch 74/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.1050 - val_accuracy: 0.9755\n",
      "Epoch 75/200\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0789 - val_accuracy: 0.9837\n",
      "Epoch 76/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0647 - val_accuracy: 0.9796\n",
      "Epoch 77/200\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9796\n",
      "Epoch 78/200\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9837\n",
      "Epoch 79/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1476 - val_accuracy: 0.9796\n",
      "Epoch 80/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9796\n",
      "Epoch 81/200\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9755\n",
      "Epoch 82/200\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.1382 - val_accuracy: 0.9755\n",
      "Epoch 83/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 6.9381e-04 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9714\n",
      "Epoch 84/200\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9755\n",
      "Epoch 85/200\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 0.9755\n",
      "Epoch 86/200\n",
      "69/69 [==============================] - 3s 40ms/step - loss: 9.5144e-04 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9755\n",
      "Epoch 87/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.1802 - val_accuracy: 0.9755\n",
      "Epoch 88/200\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.0823 - val_accuracy: 0.9837\n",
      "Epoch 89/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1098 - val_accuracy: 0.9755\n",
      "Epoch 90/200\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.1181 - val_accuracy: 0.9755\n",
      "Epoch 91/200\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.1031 - val_accuracy: 0.9755\n",
      "Epoch 92/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0952 - val_accuracy: 0.9796\n",
      "Epoch 93/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0058 - accuracy: 0.9973 - val_loss: 0.0879 - val_accuracy: 0.9755\n",
      "Epoch 94/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 0.9714\n",
      "Epoch 95/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1340 - val_accuracy: 0.9755\n",
      "Epoch 96/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1225 - val_accuracy: 0.9714\n",
      "Epoch 97/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 7.8419e-04 - accuracy: 1.0000 - val_loss: 0.1096 - val_accuracy: 0.9755\n",
      "Epoch 98/200\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 8.7372e-04 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9714\n",
      "Epoch 99/200\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 5.2728e-04 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9714\n",
      "Epoch 100/200\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 8.0041e-04 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9714\n",
      "Epoch 101/200\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0623 - val_accuracy: 0.9796\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 2s 34ms/step - loss: 7.4159e-04 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9714\n",
      "Epoch 103/200\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.1199 - val_accuracy: 0.9673\n",
      "Epoch 104/200\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 3.8474e-04 - accuracy: 1.0000 - val_loss: 0.1291 - val_accuracy: 0.9714\n",
      "Epoch 105/200\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 9.2326e-04 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9714\n",
      "Epoch 106/200\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.1181 - val_accuracy: 0.9714\n",
      "Epoch 107/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 7.2420e-04 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9755\n",
      "Epoch 108/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0898 - val_accuracy: 0.9673\n",
      "Epoch 109/200\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9673\n",
      "Epoch 110/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 6.3078e-04 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9796\n",
      "Epoch 111/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 4.8138e-04 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9673\n",
      "Epoch 112/200\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 3.9846e-04 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9673\n",
      "Epoch 113/200\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 2.1243e-04 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9755\n",
      "Epoch 114/200\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 6.0780e-04 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9796\n",
      "Epoch 115/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.1051 - val_accuracy: 0.9714\n",
      "Epoch 116/200\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 9.5972e-04 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9673\n",
      "Epoch 117/200\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 3.8789e-04 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9673\n",
      "Epoch 118/200\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 2.7014e-04 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9633\n",
      "Epoch 119/200\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 3.7510e-04 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9714\n",
      "Epoch 120/200\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 5.3911e-04 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9673\n",
      "Epoch 121/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1685 - val_accuracy: 0.9714\n",
      "Epoch 122/200\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0024 - accuracy: 0.9986 - val_loss: 0.1174 - val_accuracy: 0.9796\n",
      "Epoch 123/200\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.0833 - val_accuracy: 0.9714\n",
      "Epoch 124/200\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.1629 - val_accuracy: 0.9796\n",
      "Epoch 125/200\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 2.0511e-04 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 0.9714\n",
      "Epoch 126/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 8.4734e-04 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9714\n",
      "Epoch 127/200\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 4.1689e-04 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9755\n",
      "Epoch 128/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.2099 - val_accuracy: 0.9592\n",
      "Epoch 129/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0059 - accuracy: 0.9973 - val_loss: 0.1966 - val_accuracy: 0.9673\n",
      "Epoch 130/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1984 - val_accuracy: 0.9673\n",
      "Epoch 131/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0016 - accuracy: 0.9991 - val_loss: 0.1600 - val_accuracy: 0.9714\n",
      "Epoch 132/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1697 - val_accuracy: 0.9878\n",
      "Epoch 133/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.1704 - val_accuracy: 0.9755\n",
      "Epoch 134/200\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.1195 - val_accuracy: 0.9796\n",
      "Epoch 135/200\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.1640 - val_accuracy: 0.9796\n",
      "Epoch 136/200\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 4.6772e-04 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9796\n",
      "Epoch 137/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2001 - val_accuracy: 0.9755\n",
      "Epoch 138/200\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.0161 - accuracy: 0.9955 - val_loss: 0.0980 - val_accuracy: 0.9796\n",
      "Epoch 139/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 7.7158e-04 - accuracy: 1.0000 - val_loss: 0.0990 - val_accuracy: 0.9796\n",
      "Epoch 140/200\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0821 - val_accuracy: 0.9714\n",
      "Epoch 141/200\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.1098 - val_accuracy: 0.9878\n",
      "Epoch 142/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0059 - accuracy: 0.9977 - val_loss: 0.0889 - val_accuracy: 0.9878\n",
      "Epoch 143/200\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0102 - accuracy: 0.9977 - val_loss: 0.1166 - val_accuracy: 0.9878\n",
      "Epoch 144/200\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.0023 - accuracy: 0.9986 - val_loss: 0.1167 - val_accuracy: 0.9837\n",
      "Epoch 145/200\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.0027 - accuracy: 0.9986 - val_loss: 0.1392 - val_accuracy: 0.9837\n",
      "Epoch 146/200\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.1158 - val_accuracy: 0.9837\n",
      "Epoch 147/200\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1252 - val_accuracy: 0.9796\n",
      "Epoch 148/200\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 0.1660 - val_accuracy: 0.9796\n",
      "Epoch 149/200\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 9.4424e-04 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9755\n",
      "Epoch 150/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 5.3151e-04 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9755\n",
      "Epoch 151/200\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 1.4627e-04 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9755\n",
      "Epoch 152/200\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 2.2730e-04 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9755\n",
      "Epoch 153/200\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.2593 - val_accuracy: 0.9714\n",
      "Epoch 154/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.1690 - val_accuracy: 0.9837\n",
      "Epoch 155/200\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.0070 - accuracy: 0.9968 - val_loss: 0.2463 - val_accuracy: 0.9714\n",
      "Epoch 156/200\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0983 - val_accuracy: 0.9837\n",
      "Epoch 157/200\n",
      "69/69 [==============================] - 1s 22ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1458 - val_accuracy: 0.9755\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.1041 - val_accuracy: 0.9878\n",
      "Epoch 159/200\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.1671 - val_accuracy: 0.9796\n",
      "Epoch 160/200\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 8.9454e-04 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9837\n",
      "Epoch 161/200\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 2.6932e-04 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9837\n",
      "Epoch 162/200\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 5.9371e-04 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9878\n",
      "Epoch 163/200\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 0.0957 - val_accuracy: 0.9837\n",
      "Epoch 164/200\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 4.2328e-04 - accuracy: 0.9995 - val_loss: 0.0940 - val_accuracy: 0.9837\n",
      "Epoch 165/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 2.8712e-04 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9796\n",
      "Epoch 166/200\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 3.9503e-04 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9796\n",
      "Epoch 167/200\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 6.2197e-05 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9796\n",
      "Epoch 168/200\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 1.0942e-04 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9796\n",
      "Epoch 169/200\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 7.9072e-05 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9796\n",
      "Epoch 170/200\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 5.7594e-05 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9796\n",
      "Epoch 171/200\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 1.4974e-04 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9796\n",
      "Epoch 172/200\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.0017 - accuracy: 0.9991 - val_loss: 0.1436 - val_accuracy: 0.9796\n",
      "Epoch 173/200\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1188 - val_accuracy: 0.9837\n",
      "Epoch 174/200\n",
      "69/69 [==============================] - 3s 39ms/step - loss: 6.7601e-04 - accuracy: 0.9995 - val_loss: 0.1148 - val_accuracy: 0.9796\n",
      "Epoch 175/200\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 6.4124e-04 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9796\n",
      "Epoch 176/200\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 3.6148e-04 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9796\n",
      "Epoch 177/200\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.1948 - val_accuracy: 0.9633\n",
      "Epoch 178/200\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.2537 - val_accuracy: 0.9633\n",
      "Epoch 179/200\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.1230 - val_accuracy: 0.9714\n",
      "Epoch 180/200\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.1237 - val_accuracy: 0.9796\n",
      "Epoch 181/200\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0056 - accuracy: 0.9977 - val_loss: 0.2370 - val_accuracy: 0.9714\n",
      "Epoch 182/200\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.1347 - val_accuracy: 0.9796\n",
      "Epoch 183/200\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 6.3172e-04 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.9796\n",
      "Epoch 184/200\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 1.4320e-04 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9837\n",
      "Epoch 185/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.1656 - val_accuracy: 0.9837\n",
      "Epoch 186/200\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.2760 - val_accuracy: 0.9714\n",
      "Epoch 187/200\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0034 - accuracy: 0.9986 - val_loss: 0.2091 - val_accuracy: 0.9837\n",
      "Epoch 188/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0117 - accuracy: 0.9986 - val_loss: 0.2203 - val_accuracy: 0.9796\n",
      "Epoch 189/200\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.1748 - val_accuracy: 0.9796\n",
      "Epoch 190/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 1.5188e-04 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9755\n",
      "Epoch 191/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.1939 - val_accuracy: 0.9755\n",
      "Epoch 192/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.1900 - val_accuracy: 0.9796\n",
      "Epoch 193/200\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 1.7180e-04 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9796\n",
      "Epoch 194/200\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.2725 - val_accuracy: 0.9673\n",
      "Epoch 195/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1127 - val_accuracy: 0.9837\n",
      "Epoch 196/200\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 5.8235e-04 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9755\n",
      "Epoch 197/200\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 2.0399e-04 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 0.9714\n",
      "Epoch 198/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 2.9915e-04 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9755\n",
      "Epoch 199/200\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 2.6327e-04 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9755\n",
      "Epoch 200/200\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.2259e-04 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9755\n",
      "Test loss: 0.2211916744709015\n",
      "Test accuracy: 0.9682353138923645\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#引入各項需要的lib\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "\n",
    "def data_x_y_preprocess(datapath):\n",
    "    img_row, img_col = 28, 28  #圖片大小28*28\n",
    "    datapath = datapath  #資料路徑\n",
    "    data_x = np.zeros((28, 28)).reshape(1, 28, 28)  #儲存圖片\n",
    "    pictureCount = 0  #紀錄圖片數量以便reshape\n",
    "    data_y = []  #紀錄label\n",
    "    num_class = 10  #圖片種類有10種\n",
    "    for root, dirs, files in os.walk(datapath):  #遍歷所有路境內的檔案\n",
    "        if(\".DS_Store\" in files):#因為mac出現隱藏檔 所以跳過.DS_Store\n",
    "            continue\n",
    "        #print(root)\n",
    "        for f in files:  #找出檔案\n",
    "            #print(f)\n",
    "            label = int(root.split(\"/\")[-1])  #取得label\n",
    "            data_y.append(label)  #將label放入data_y\n",
    "            fullpath = os.path.join(root, f)  #求出正確的fullpath\n",
    "            img = Image.open(fullpath)  #開啟照片\n",
    "            img = (np.array(img) / 255).reshape(1, 28, 28)  #讀出照片並且做正規化reshape\n",
    "            data_x = np.vstack((data_x, img))  #處理完成後加入data_x\n",
    "            pictureCount += 1  #count +1\n",
    "    data_x = np.delete(data_x, [0], 0)  #delete np.zeros\n",
    "    data_x = data_x.reshape(pictureCount, img_row, img_col, 1)  #reshape （圖片張數，img_row, img_col, 色彩通道（灰階））\n",
    "    data_y = np_utils.to_categorical(data_y, num_class)  #將label轉成one-hot encoding\n",
    "    return data_x, data_y  #回傳處理好的資料\n",
    "\n",
    "\n",
    "#從train_image資料夾取得資料\n",
    "datapath='./handwrite__detect/train_image'\n",
    "data_X, data_Y = data_x_y_preprocess(datapath)\n",
    "\n",
    "#從test_image資料夾取得資料\n",
    "datapath='./handwrite__detect/test_image'\n",
    "data_test_X, data_test_Y = data_x_y_preprocess(datapath)\n",
    "    \n",
    "model = Sequential()  #線性執行模型\n",
    "\n",
    "#建立卷基層，filters數目32，kernel_size=3*3，並且使用relu，且加入第一層卷積層時要有input shape\n",
    "model.add(\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  #建立池化層，大小2*2，maxpooling\n",
    "\n",
    "#建立卷基層，filtersj數目64，kernel_size=3*3，使用relu\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  #建立池化層，大小2*2，maxpooling\n",
    "\n",
    "model.add(Dropout(0.1))  #prevent from overfitting，隨機Dropout神經元，斷開比例0.1\n",
    "model.add(Flatten())  #使用Flatten將2D輸入成1D，使用於卷積層道全連接層的過度\n",
    "model.add(Dropout(0.1))  #prevent from overfitting，隨機Dropout神經元，斷開比例0.1\n",
    "model.add(Dense(128, activation='relu'))  #建立全連階層，128個輸出，使用relu\n",
    "model.add(Dropout(0.25))  #prevent from overfitting，隨機Dropout神經元，斷開比例0.25\n",
    "model.add(Dense(units=10, activation='softmax'))  #建立全連階層，10個輸出，並且使用softmax，將ouput轉換到[0,1]間\n",
    "\n",
    "model.summary()  \n",
    "\n",
    "#建立模型後，將模型進行編譯，選擇損失函數、優化方式及成效衡量方式\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#訓練過程，訓練資料集，訓練資料的label 儲存於train_history之中，且200次的訓練次數，用0.1的驗證集資料比例做檢查監視\n",
    "train_history = model.fit(data_X,\n",
    "                          data_Y,\n",
    "                          batch_size=16,\n",
    "                          epochs=200,\n",
    "                          verbose=1,\n",
    "                          validation_split=0.1)\n",
    "\n",
    "\n",
    "\n",
    "#顯示損失函數，個階段訓練成果\n",
    "score = model.evaluate(data_test_X, data_test_Y, verbose=0)\n",
    "print('Test loss:', score[0])  #輸出Test loss\n",
    "print('Test accuracy:', score[1])  #輸出Test accuracy\n",
    "\n",
    "#優化訓練曲線\n",
    "plt.plot(train_history.history['loss'])  #輸出訓練過程中的loss\n",
    "plt.plot(train_history.history['val_loss'])  #輸出訓練過程中的val_loss\n",
    "plt.title('Train History')  #圖片title\n",
    "plt.ylabel('loss')  #圖片ylabel\n",
    "plt.xlabel('Epoch')  #圖片xlabel\n",
    "plt.legend(['loss', 'val_loss'], loc='upper left')  #左上角圖片圖例\n",
    "plt.show()  #圖片輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d66cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
